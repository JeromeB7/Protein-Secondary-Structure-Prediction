{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "x8MLNSh_H_-W",
        "outputId": "7106b3f7-ae97-43df-ea82-c3777d329922"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Buffered data was truncated after reaching the output size limit."
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load embeddings from CSV\n",
        "embedding_df = pd.read_csv(\"casp12_embeddings.csv\")\n",
        "\n",
        "# Assuming the first column is an identifier, extract numerical embeddings\n",
        "X = embedding_df.iloc[:, 1:].values.astype(np.float32)\n",
        "\n",
        "# Load labels\n",
        "y = pd.read_csv(\"CASP12.csv\")\n",
        "y_q3 = y[\"dssp3\"].to_list()\n",
        "\n",
        "# Encode Q3 labels\n",
        "q3_classes = [\"H\", \"E\", \"C\"]\n",
        "q3_encoder = LabelEncoder()\n",
        "q3_encoder.fit(q3_classes)\n",
        "y_encoded = q3_encoder.transform(y_q3)\n",
        "y_encoded = to_categorical(y_encoded, num_classes=len(q3_classes))  # One-hot encoding\n",
        "\n",
        "# Split into train and test sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the MLP model\n",
        "model = Sequential([\n",
        "    Input(shape=(1024,)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(3, activation='softmax')  # Output layer for Q3 classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=15, batch_size=64, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "y_test_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Print classification report\n",
        "print(\"Q3 Classification Report:\")\n",
        "print(classification_report(y_test_labels, y_pred_labels, target_names=q3_classes))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-eKyv2gIdAn",
        "outputId": "a0d5daa8-4432-4a45-b4da-7cce42ef4a37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.1767 - loss: 2.2590 - val_accuracy: 0.3252 - val_loss: 1.8463\n",
            "Epoch 2/30\n",
            "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.2868 - loss: 1.8145 - val_accuracy: 0.3642 - val_loss: 1.6958\n",
            "Epoch 3/30\n",
            "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.3454 - loss: 1.7068 - val_accuracy: 0.4048 - val_loss: 1.6095\n",
            "Epoch 4/30\n",
            "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.3855 - loss: 1.6160 - val_accuracy: 0.4587 - val_loss: 1.5019\n",
            "Epoch 5/30\n",
            "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4172 - loss: 1.4747 - val_accuracy: 0.4590 - val_loss: 1.4730\n",
            "Epoch 6/30\n",
            "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4475 - loss: 1.3911 - val_accuracy: 0.4992 - val_loss: 1.3757\n",
            "Epoch 7/30\n",
            "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.4659 - loss: 1.3327 - val_accuracy: 0.4841 - val_loss: 1.3838\n",
            "Epoch 8/30\n",
            "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4821 - loss: 1.2892 - val_accuracy: 0.4880 - val_loss: 1.3628\n",
            "Epoch 9/30\n",
            "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.4916 - loss: 1.2838 - val_accuracy: 0.4932 - val_loss: 1.3647\n",
            "Epoch 10/30\n",
            "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5035 - loss: 1.2121 - val_accuracy: 0.5162 - val_loss: 1.3230\n",
            "Epoch 11/30\n",
            "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5037 - loss: 1.1718 - val_accuracy: 0.5275 - val_loss: 1.2600\n",
            "Epoch 12/30\n",
            "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.5309 - loss: 1.1246 - val_accuracy: 0.5147 - val_loss: 1.2919\n",
            "Epoch 13/30\n",
            "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.5305 - loss: 1.0975 - val_accuracy: 0.5228 - val_loss: 1.2904\n",
            "Epoch 14/30\n",
            "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5385 - loss: 1.0787 - val_accuracy: 0.5262 - val_loss: 1.2953\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "Q8 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           H       0.05      0.17      0.08        58\n",
            "           E       0.73      0.31      0.44      1510\n",
            "           G       0.68      0.74      0.71      1033\n",
            "           I       0.13      0.45      0.20       192\n",
            "           B       0.89      0.66      0.76      2070\n",
            "           T       0.28      0.58      0.38        33\n",
            "           S       0.19      0.43      0.27       442\n",
            "           C       0.31      0.37      0.34       603\n",
            "\n",
            "    accuracy                           0.53      5941\n",
            "   macro avg       0.41      0.46      0.40      5941\n",
            "weighted avg       0.66      0.53      0.56      5941\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Load embeddings\n",
        "with open(\"/content/drive/MyDrive/PSSP/ts115_embeddings.json\", \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Load labels\n",
        "y = pd.read_csv(\"TS115.csv\")\n",
        "y_q8 = y[\"dssp8\"].to_list()\n",
        "\n",
        "# Ensure embeddings match label length\n",
        "all_embeddings_list = []\n",
        "labels = []\n",
        "for protein, label_seq in zip(data.values(), y_q8):\n",
        "    trimmed_protein = protein[:len(label_seq)]  # Trim excess embeddings\n",
        "    all_embeddings_list.extend(trimmed_protein)\n",
        "    labels.extend(label_seq)\n",
        "\n",
        "# Convert to NumPy arrays\n",
        "X = np.array(all_embeddings_list, dtype=np.float32)\n",
        "\n",
        "# Encode Q8 labels\n",
        "q8_classes = [\"H\", \"E\", \"G\", \"I\", \"B\", \"T\", \"S\", \"C\"]\n",
        "q8_encoder = LabelEncoder()\n",
        "q8_encoder.fit(q8_classes)\n",
        "y_encoded = q8_encoder.transform(labels)\n",
        "y_encoded = to_categorical(y_encoded, num_classes=len(q8_classes))  # One-hot encoding\n",
        "\n",
        "# Compute class weights for handling imbalance\n",
        "class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_encoded.argmax(axis=1)), y=y_encoded.argmax(axis=1))\n",
        "class_weights_dict = {i: class_weights[i] for i in range(len(q8_classes))}\n",
        "\n",
        "# Split into train and test sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the improved MLP model\n",
        "model = Sequential([\n",
        "    Input(shape=(1024,)),\n",
        "    Dense(128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(64, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(32, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(16, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Dense(8, activation='softmax')  # Output layer for Q8 classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Add EarlyStopping to stop training if val_loss increases for 3 epochs\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=30, batch_size=64, validation_data=(X_test, y_test),\n",
        "          class_weight=class_weights_dict, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "y_test_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Print classification report\n",
        "print(\"Q8 Classification Report:\")\n",
        "print(classification_report(y_test_labels, y_pred_labels, target_names=q8_classes))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "talCWynlJSsa"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}